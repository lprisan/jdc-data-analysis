---
title: "Studying teacher cognitive load using eyetracking"
output: html_document
bibliography: eyetracking.bibtex
---

This small document contains the main code and results of our analysis of...

We have used recordings from different subjects and kinds of formal education settings:

* Three collaborative learning sessions where primary school students used a tabletop tangible interface to learn fractions. The "teacher" was a researcher with relatively little teaching experience (marked T1S2, T1S3, T1S6)
* Two lectures recorded in (computer science) university courses, given by two different (expert) teachers (marked T2S1, T3S1)
* ...

The following sections explain the process of analysis followed ...

Pre-requisites and data pre-processing
-------------------------------------------

The main input for the following analyses is the raw event data from the recording of the sessions (in the SMI mobile eye-trackers, use the menu ...), as well as saccade and fixation event details, also exported as comma-separated files (use the menu ...).

1. From these raw data files, we extract a sequence of eye-tracking events, which we use as a base to estimate the subjects' cognitive load, namely, the pupil diameter, fixation length and saccade speed
2. Then, from these events, we extract the four metrics that, based on @Buettner2013, can be used to estimate the cognitive load, over sliding windows of 10s, with 5 second step/slide:
    * Average pupil diameter
    * Standard deviation of the pupil diameter
    * Number of fixations >500ms
    * Average saccade speed

**TODO: Change fields to extract from number to name, plus manual addition of Dummy field in raw data**


```{r, cache=TRUE, echo=FALSE, message=FALSE}
# Some basic parameters for the sliding windows (in seconds)
window <- 10
slide <- 5

# (in Mirko's original labeling, Pierre02 corresponds to T2S1, Roland03 is T3S1, JdCSession2 is T1S1)
sessions <- c("T1S1","T2S1","T3S1")
for (session in sessions){
    
    # We check whether the clean data is already in place - if so, we skip this pre-processing
    if(!file.exists(paste("./rawdata/",session,".EyetrackerEvents.rda",sep="")) ||
        !file.exists(paste("./rawdata/",session,".EyetrackerFixations.rda",sep="")) ||
        !file.exists(paste("./rawdata/",session,".EyetrackerSaccades.rda",sep=""))){
        
        # We load the raw events export
        filename = paste("./rawdata/",session,"-events-export.txt", sep="")
        filedata <- read.csv(filename,as.is=T,comment.char="#")
        
        # From all the data, we only need timestamp, pupil diameter (L,R, in mm)
        filedata <- filedata[c(1,6,9)]
        filedata$Session <- session
        pupildata <- data.frame(filedata)
    
        # We calculate the time baseline of the session
        time0 <- min(pupildata$Time)
        pupildata$Time.ms <- (pupildata$Time - time0) / 1000
        
        # We load the fixation details file
        filename = paste("./rawdata/",session,"-fixation-details.txt", sep="")
        filedata <- read.csv(filename,comment.char="#")
        
        # we select the meaningful columns (for now, only fixation start, duration, end in ms)
        # it is different in the exports we have for different teachers!
        if(substr(session,1,2)!="T1"){
            filedata <- filedata[,c(7,8,9)]
        }else{
            filedata <- filedata[,c(8,9,10)]
        }
        filedata$Session <- session
        fixdata <- data.frame(filedata)
    
        #We set the time of the fixation in the middle of the fixation
        fixdata$Time.ms <- (fixdata$Fixation.Start..ms. + (fixdata$Fixation.Duration..ms./2)) 
        # We create a Time field so that we have the time in both timestamp and ms formats
        fixdata$Time <- time0 + (fixdata$Time.ms)*1000
    
        # We load the saccade details file
        filename = paste("./rawdata/",session,"-saccade-details.txt", sep="")
        filedata <- read.csv(filename,comment.char="#")
        
        # we select the meaningful columns (for now, only saccade start, duration, end in ms and amplitude in degrees)
        # it is different in the exports we have for different teachers!
        if(substr(session,1,2)!="T1"){
            filedata <- filedata[,c(7,8,9,14)]
        }else{
            filedata <- filedata[,c(8,9,10,15)]
        }        
        filedata$Session <- session
        sacdata <- data.frame(filedata)
        # We add the saccade speed for each saccade
        sacdata$Saccade.Speed <- sacdata$Amplitude.... / sacdata$Saccade.Duration..ms.
    
        #We set the time of saccade in the middle of the fixation
        sacdata$Time.ms <- (sacdata$Saccade.Start..ms. + (sacdata$Saccade.Duration..ms./2)) 
        # We create a Time field so that we have the time in both timestamp and ms formats
        sacdata$Time <- time0 + (sacdata$Time.ms)*1000
        
        # We save the clean(er) data to smaller, more efficient rda files
        save(pupildata,file=paste("./rawdata/",session,".EyetrackerEvents.rda",sep=""),compress=TRUE)
        save(fixdata,file=paste("./rawdata/",session,".EyetrackerFixations.rda",sep=""),compress=TRUE)
        save(sacdata,file=paste("./rawdata/",session,".EyetrackerSaccades.rda",sep=""),compress=TRUE)
        
    }
    
    # We load the clean data, just in case we did not the previous steps
    pupildata <- get(load(paste("./rawdata/",session,".EyetrackerEvents.rda",sep="")))
    fixdata <- get(load(paste("./rawdata/",session,".EyetrackerFixations.rda",sep="")))
    sacdata <- get(load(paste("./rawdata/",session,".EyetrackerSaccades.rda",sep="")))

    # We load a few functions that will be useful for the rolling window calculations
    source("JDCEyetrackingAnalysis.R")
    
    # We get the rolling window for the mean pupil diameter, and its median value for a median cut
    meandata <- rollingMean(pupildata$Time.ms,pupildata$L.Pupil.Diameter..mm.,window*1000,slide*1000)
    meanPDmedian <- median(meandata$value)
    meandata$above <- as.numeric(meandata$value > meanPDmedian)
    
    # We get the rolling window for the SD of pupil diameter, and its median value for a median cut
    sddata <- rollingSd(pupildata$Time.ms,pupildata$L.Pupil.Diameter..mm.,window*1000,slide*1000)
    sdPDmedian <- median(sddata$value)
    sddata$above <- as.numeric(sddata$value > sdPDmedian)

    # We get the number of long fixations in the window, and its median
    longdata <- rollingLong(fixdata$Time.ms,fixdata$Fixation.Duration..ms.,window*1000,slide*1000)
    longFixMedian <- median(longdata$value)
    longdata$above <- as.numeric(longdata$value > longFixMedian)

    # We get the saccade speed in the window
    sacspdata <- rollingMean(sacdata$Time.ms,sacdata$Saccade.Speed,window*1000,slide*1000)
    sacSpMedian <- median(sacspdata$value)
    sacspdata$above <- as.numeric(sacspdata$value > sacSpMedian)
    
    totaldata <- merge(meandata,sddata,by="time",suffixes = c(".Mean",".SD"),all=T)
    totaldata <- merge(totaldata,longdata,by="time",all=T)
    names(totaldata)[[6]] <- paste(names(totaldata)[[6]],"Fix",sep=".")
    names(totaldata)[[7]] <- paste(names(totaldata)[[7]],"Fix",sep=".")
    totaldata <- merge(totaldata,sacspdata,by="time",all=T)
    names(totaldata)[[8]] <- paste(names(totaldata)[[8]],"Sac",sep=".")
    names(totaldata)[[9]] <- paste(names(totaldata)[[9]],"Sac",sep=".")

    totaldata$Load <- totaldata$above.Mean + totaldata$above.SD + totaldata$above.Fix + totaldata$above.Sac

    # We save all the (clean) window data in a file, for later use
    save(totaldata,meanPDmedian,sdPDmedian,longFixMedian,sacSpMedian,file=paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))
    
}
```

After doing this pre-processing, we have a data frame per each session, looking like:

```{r}
session <- sessions[1]
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))
head(totaldata, n=3)
```

Analysis for T1S1 (Luis, novice teacher, collaborative situation)
----------------------------------------------------

We can inspect the different eyetracking parameters during this session, as well as our estimation of cognitive load of the teacher, calculated as **how many of these metrics surpass the median of the session**:

```{r, message=FALSE, echo=FALSE, fig.height=2, fig.width=8}
require(ggplot2)
session <- "T1S1"
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))

p1 <- ggplot(totaldata, aes(x=time, y=value.Mean)) + 
  ggtitle(paste("Pupil diameter MEAN over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=meanPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p1)

p2 <- ggplot(totaldata, aes(x=time, y=value.SD)) + 
  ggtitle(paste("Pupil diameter SD over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sdPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p2)

p3 <- ggplot(totaldata, aes(x=time, y=value.Fix)) + 
  ggtitle(paste("Fixations >500ms over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=longFixMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p3)

p4 <- ggplot(totaldata, aes(x=time, y=value.Sac)) + 
  ggtitle(paste("Saccade speed over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sacSpMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p4)

p5 <- ggplot(totaldata, aes(x=time, y=Load, col=Load)) + 
  ggtitle(paste("Load Index\n(estimation of cognitive overload over ",window,"s)",sep="")) + 
  geom_line(size=1) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
  scale_color_gradient(low="green",high="red")
print(p5)

```

We can draw a simple histogram of the load, to get an idea of its distribution:

```{r}
qplot(totaldata$Load, binwidth=1)
```

In this case, the distribution is less normal-looking, with bigger tails than in the following cases, and the proportion of high-load moments is higher than in the other ones (which may evidence the fact that it was a very novel situation for the teacher).

We can see how correlated these four measurements are to each other:

```{r}
#library(corrgram)

cor(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")])

#corrgram(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")], order=F, lower.panel=panel.shade,
#  upper.panel=panel.pie, text.panel=panel.txt,
#  main="Cognitive load metrics")
```

The correlations are very far from perfect, but they are much higher and more positive than the other examples we will see later.

We can now save the moments of maximum and minimum (estimated) load of the teacher, for later (manual) video coding. In our case, we already have the video coding data from a previous analysis iteration.............................

```{r}
interesting <- totaldata[totaldata$Load>=max(totaldata$Load) | totaldata$Load<=min(totaldata$Load),c("time","Load")]
dataToLook <- as.data.frame(interesting)
names(dataToLook)[[1]] <- "Time.ms"
dataToLook$Time.min <- msToMinSec(dataToLook$Time.ms)
dataToLook$Session <- session

write.csv(dataToLook, file=paste("./cleandata/InterestingEpisodes.",session,".window",window,"s.slide",slide,"s.csv",sep=""))

# We load the two video coding data files, and extract/merge the interesting episodes from it
videocode <- read.csv("./cleandata/VideoCoding.T1S1.T1S2.T1S3.Load0.csv")
videocode <- rbind(videocode,read.csv("./cleandata/VideoCoding.T1S1.T1S2.T1S3.Load3.csv"))
videocode <- videocode[videocode$Session==2,]

dataToLook <- merge(dataToLook,videocode,by="Time.ms")

# We now do some tables with the video coded occurrences, and calculate some basic chi-squared tests of independence
dataToLook$Load <- as.factor(dataToLook$Load.x)

print(tabAct <- table(dataToLook$Load,dataToLook$Activity))
print(chisq.test(tabAct))

print(tabSoc <- table(dataToLook$Load,dataToLook$Social))
print(chisq.test(tabSoc))

# We refactor the Focus factor, as there are factors that do not appear
dataToLook$Focus <- factor(dataToLook$Focus)
print(tabFoc <- table(dataToLook$Load,dataToLook$Focus))
print(chisq.test(tabFoc))

print(tabCha <- table(dataToLook$Load,dataToLook$Changing.visual.field.a.lot))
print(chisq.test(tabCha))
```

As we can see, in this case the **load seems to be clearly related to the focus, social plane and changes in visual field**. The relationship with the kind of activity being done by the teacher is not statistically significant. High load episodes seem to happen more often in the classroom social plane, while looking at the faces or backs of students, or at the manipulative (teacher) desk. Low load episodes happen exclusively at the group social plane, while looking at the tabletop without great changes in visual field.





Analysis for T2S1 (Pierre, expert teacher, lecture)
------------------------------------------------

We can inspect the different eyetracking parameters during this session, as well as our estimation of cognitive load of the teacher, calculated as **how many of these metrics surpass the median of the session**:

```{r, message=FALSE, echo=FALSE, fig.height=2, fig.width=8}
require(ggplot2)
session <- "T2S1"
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))

p1 <- ggplot(totaldata, aes(x=time, y=value.Mean)) + 
  ggtitle(paste("Pupil diameter MEAN over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=meanPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p1)

p2 <- ggplot(totaldata, aes(x=time, y=value.SD)) + 
  ggtitle(paste("Pupil diameter SD over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sdPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p2)

p3 <- ggplot(totaldata, aes(x=time, y=value.Fix)) + 
  ggtitle(paste("Fixations >500ms over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=longFixMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p3)

p4 <- ggplot(totaldata, aes(x=time, y=value.Sac)) + 
  ggtitle(paste("Saccade speed over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sacSpMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p4)

p5 <- ggplot(totaldata, aes(x=time, y=Load, col=Load)) + 
  ggtitle(paste("Load Index\n(estimation of cognitive overload over ",window,"s)",sep="")) + 
  geom_line(size=1) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
  scale_color_gradient(low="green",high="red")
print(p5)

```

We can draw a simple histogram of the load, to get an idea of its distribution:

```{r}
qplot(totaldata$Load, binwidth=1)
```

We can see how correlated these four measurements are to each other:

```{r}
#library(corrgram)

cor(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")])

#corrgram(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")], order=F, lower.panel=panel.shade,
#  upper.panel=panel.pie, text.panel=panel.txt,
#  main="Cognitive load metrics")
```

Oddly enough, **most of the correlations are negative**!


We can now save the moments of maximum and minimum (estimated) load of the teacher, for later (manual) video coding.

```{r}
interesting <- totaldata[totaldata$Load>=max(totaldata$Load) | totaldata$Load<=min(totaldata$Load),c("time","Load")]
dataToLook <- as.data.frame(interesting)
names(dataToLook)[[1]] <- "Time.ms"
dataToLook$Time.min <- msToMinSec(dataToLook$Time.ms)
dataToLook$Session <- session

write.csv(dataToLook, file=paste("./cleandata/InterestingEpisodes.",session,".window",window,"s.slide",slide,"s.csv",sep=""))
```

An initial inspection (descriptive narration) of the highest (Load=4) and lowest (Load=0) load moments indicates that the high load moments (very scarce) include the eyetracker calibration and preparation to start, some quick question/answer exchanges with students, pauses while preparing what to say in the next stretch of talk, but also some episodes of just talking and scanning the audience. Low load episodes include parts of talking and scanning the audience, but there is a high proportion of moments of looking/reading at the laptop slides sustainedly.

Analysis for T3S1 (Roland, expert teacher, lecture with clickers interruptions)
------------------------------------------------

We can inspect the different eyetracking parameters during this session, as well as our estimation of cognitive load of the teacher, calculated as **how many of these metrics surpass the median of the session**:

```{r, message=FALSE, echo=FALSE, fig.height=2, fig.width=8}
require(ggplot2)
session <- "T3S1"
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))

# We eliminate non-complete intervals (the end of the fixation and saccade data appears to be missing)
totaldata <- totaldata[complete.cases(totaldata),]
#TODO: check why???**


p1 <- ggplot(totaldata, aes(x=time, y=value.Mean)) + 
  ggtitle(paste("Pupil diameter MEAN over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=meanPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p1)

p2 <- ggplot(totaldata, aes(x=time, y=value.SD)) + 
  ggtitle(paste("Pupil diameter SD over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sdPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p2)

p3 <- ggplot(totaldata, aes(x=time, y=value.Fix)) + 
  ggtitle(paste("Fixations >500ms over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=longFixMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p3)

p4 <- ggplot(totaldata, aes(x=time, y=value.Sac)) + 
  ggtitle(paste("Saccade speed over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sacSpMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p4)

p5 <- ggplot(totaldata, aes(x=time, y=Load, col=Load)) + 
  ggtitle(paste("Load Index\n(estimation of cognitive overload over ",window,"s)",sep="")) + 
  geom_line(size=1) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
  scale_color_gradient(low="green",high="red")
print(p5)

```

We can draw a simple histogram of the load, to get an idea of its distribution:

```{r}
qplot(totaldata$Load, binwidth=1)
```

We can see how correlated these four measurements are to each other:

```{r}
#library(corrgram)
cor(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")])

#corrgram(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")], order=F, lower.panel=panel.shade,
#  upper.panel=panel.pie, text.panel=panel.txt,
#  main="Cognitive load metrics")
```

We can see how, again, most of the **correlations are negative, and in general quite small!**

We can now save the moments of maximum and minimum (estimated) load of the teacher, for later (manual) video coding.

```{r}
interesting <- totaldata[totaldata$Load>=max(totaldata$Load) | totaldata$Load<=min(totaldata$Load),c("time","Load")]
dataToLook <- as.data.frame(interesting)
names(dataToLook)[[1]] <- "Time.ms"
dataToLook$Time.min <- msToMinSec(dataToLook$Time.ms)
dataToLook$Session <- session

write.csv(dataToLook, file=paste("./cleandata/InterestingEpisodes.",session,".window",window,"s.slide",slide,"s.csv",sep=""))
```

An initial inspection (descriptive narration) of the highest and lowest load moments indicates that **there is not a clear trend** in their nature. High load moments often seem to involve the teacher moving his head a lot (from projection to audience and viceversa), quick question-answer exchanges, or losing the train of thought, or unexpected occurrences like a student arriving late. Low load moments include the teacher talking and scanning the audience (but these are also sometimes in the high load set), pauses waiting for other people to respond or explain things, sp. during the initial setup of the lecture and some pauses that were not about the lecture itself (Mirko's experiments on attention).

References
--------------------------------
