---
title: "Studying teacher cognitive load using eyetracking"
output: html_document
bibliography: eyetracking.bibtex
---

This small document contains the main code and results of our analysis of...

We have used recordings from different subjects and kinds of formal education settings:

* Three collaborative learning sessions where primary school students used a tabletop tangible interface to learn fractions. The "teacher" was a researcher with relatively little teaching experience (marked T1S2, T1S3, T1S6)
* Two lectures recorded in (computer science) university courses, given by two different (expert) teachers (marked T2S1, T3S1)
* ...

The following sections explain the process of analysis followed ...

Pre-requisites and data pre-processing
-------------------------------------------

The main input for the following analyses is the raw event data from the recording of the sessions (in the SMI mobile eye-trackers, use the menu ...), as well as saccade and fixation event details, also exported as comma-separated files (use the menu ...).

1. From these raw data files, we extract a sequence of eye-tracking events, which we use as a base to estimate the subjects' cognitive load, namely, the pupil diameter, fixation length and saccade speed
2. Then, from these events, we extract the four metrics that, based on @Buettner2013, can be used to estimate the cognitive load, over sliding windows of 10s, with 5 second step/slide:
    * Average pupil diameter
    * Standard deviation of the pupil diameter
    * Number of fixations >500ms
    * Average saccade speed

**TODO: Change fields to extract from number to name, plus manual addition of Dummy field in raw data**


```{r, cache=TRUE, echo=FALSE, message=FALSE}
# Some basic parameters for the sliding windows (in seconds)
window <- 10
slide <- 5

# (in Mirko's original labeling, Pierre02 corresponds to T2S1, Roland03 is T3S1)
sessions <- c("T2S1","T3S1")
for (session in sessions){
    
    # We check whether the clean data is already in place - if so, we skip this pre-processing
    if(!file.exists(paste("./rawdata/",session,".EyetrackerEvents.rda",sep="")) ||
        !file.exists(paste("./rawdata/",session,".EyetrackerFixations.rda",sep="")) ||
        !file.exists(paste("./rawdata/",session,".EyetrackerSaccades.rda",sep=""))){
        
        # We load the raw events export
        filename = paste("./rawdata/",session,"-events-export.txt", sep="")
        filedata <- read.csv(filename,as.is=T,comment.char="#")
        
        # From all the data, we only need timestamp, pupil diameter (L,R, in mm)
        filedata <- filedata[c(1,6,9)]
        filedata$Session <- session
        pupildata <- data.frame(filedata)
    
        # We calculate the time baseline of the session
        time0 <- min(pupildata$Time)
        pupildata$Time.ms <- (pupildata$Time - time0) / 1000
        
        # We load the fixation details file
        filename = paste("./rawdata/",session,"-fixation-details.txt", sep="")
        filedata <- read.csv(filename,comment.char="#")
        
        # we select the meaningful columns (for now, only fixation start, duration, end in ms)
        filedata <- filedata[c(7,8,9)] # TODO: In the JdC files, it is 8,9,10!!
        filedata$Session <- session
        fixdata <- data.frame(filedata)
    
        #We set the time of the fixation in the middle of the fixation
        fixdata$Time.ms <- (fixdata$Fixation.Start..ms. + (fixdata$Fixation.Duration..ms./2)) 
        # We create a Time field so that we have the time in both timestamp and ms formats
        fixdata$Time <- time0 + (fixdata$Time.ms)*1000
    
        # We load the saccade details file
        filename = paste("./rawdata/",session,"-saccade-details.txt", sep="")
        filedata <- read.csv(filename,comment.char="#")
        
        # we select the meaningful columns (for now, only saccade start, duration, end in ms and amplitude in degrees)
        filedata <- filedata[c(7,8,9,14)] # TODO: In the JdC files, it is 8,9,10,15!!
        filedata$Session <- session
        sacdata <- data.frame(filedata)
        # We add the saccade speed for each saccade
        sacdata$Saccade.Speed <- sacdata$Amplitude.... / sacdata$Saccade.Duration..ms.
    
        #We set the time of saccade in the middle of the fixation
        sacdata$Time.ms <- (sacdata$Saccade.Start..ms. + (sacdata$Saccade.Duration..ms./2)) 
        # We create a Time field so that we have the time in both timestamp and ms formats
        sacdata$Time <- time0 + (sacdata$Time.ms)*1000
        
        # We save the clean(er) data to smaller, more efficient rda files
        save(pupildata,file=paste("./rawdata/",session,".EyetrackerEvents.rda",sep=""),compress=TRUE)
        save(fixdata,file=paste("./rawdata/",session,".EyetrackerFixations.rda",sep=""),compress=TRUE)
        save(sacdata,file=paste("./rawdata/",session,".EyetrackerSaccades.rda",sep=""),compress=TRUE)
        
    }
    
    # We load the clean data, just in case we did not the previous steps
    pupildata <- get(load(paste("./rawdata/",session,".EyetrackerEvents.rda",sep="")))
    fixdata <- get(load(paste("./rawdata/",session,".EyetrackerFixations.rda",sep="")))
    sacdata <- get(load(paste("./rawdata/",session,".EyetrackerSaccades.rda",sep="")))

    # We load a few functions that will be useful for the rolling window calculations
    source("JDCEyetrackingAnalysis.R")
    
    # We get the rolling window for the mean pupil diameter, and its median value for a median cut
    meandata <- rollingMean(pupildata$Time.ms,pupildata$L.Pupil.Diameter..mm.,window*1000,slide*1000)
    meanPDmedian <- median(meandata$value)
    meandata$above <- as.numeric(meandata$value > meanPDmedian)
    
    # We get the rolling window for the SD of pupil diameter, and its median value for a median cut
    sddata <- rollingSd(pupildata$Time.ms,pupildata$L.Pupil.Diameter..mm.,window*1000,slide*1000)
    sdPDmedian <- median(sddata$value)
    sddata$above <- as.numeric(sddata$value > sdPDmedian)

    # We get the number of long fixations in the window, and its median
    longdata <- rollingLong(fixdata$Time.ms,fixdata$Fixation.Duration..ms.,window*1000,slide*1000)
    longFixMedian <- median(longdata$value)
    longdata$above <- as.numeric(longdata$value > longFixMedian)

    # We get the saccade speed in the window
    sacspdata <- rollingMean(sacdata$Time.ms,sacdata$Saccade.Speed,window*1000,slide*1000)
    sacSpMedian <- median(sacspdata$value)
    sacspdata$above <- as.numeric(sacspdata$value > sacSpMedian)
    
    totaldata <- merge(meandata,sddata,by="time",suffixes = c(".Mean",".SD"),all=T)
    totaldata <- merge(totaldata,longdata,by="time",all=T)
    names(totaldata)[[6]] <- paste(names(totaldata)[[6]],"Fix",sep=".")
    names(totaldata)[[7]] <- paste(names(totaldata)[[7]],"Fix",sep=".")
    totaldata <- merge(totaldata,sacspdata,by="time",all=T)
    names(totaldata)[[8]] <- paste(names(totaldata)[[8]],"Sac",sep=".")
    names(totaldata)[[9]] <- paste(names(totaldata)[[9]],"Sac",sep=".")

    totaldata$Load <- totaldata$above.Mean + totaldata$above.SD + totaldata$above.Fix + totaldata$above.Sac

    # We save all the (clean) window data in a file, for later use
    save(totaldata,meanPDmedian,sdPDmedian,longFixMedian,sacSpMedian,file=paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))
    
}
```

After doing this pre-processing, we have a data frame per each session, looking like:

```{r}
session <- sessions[1]
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))
head(totaldata, n=3)
```

Analysis for T2S1 (Pierre)
------------------------------------------------

We can inspect the different eyetracking parameters during this session, as well as our estimation of cognitive load of the teacher, calculated as **how many of these metrics surpass the median of the session**:

```{r, message=FALSE, echo=FALSE, fig.height=2, fig.width=8}
require(ggplot2)
session <- "T2S1"
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))

p1 <- ggplot(totaldata, aes(x=time, y=value.Mean)) + 
  ggtitle(paste("Pupil diameter MEAN over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=meanPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p1)

p2 <- ggplot(totaldata, aes(x=time, y=value.SD)) + 
  ggtitle(paste("Pupil diameter SD over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sdPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p2)

p3 <- ggplot(totaldata, aes(x=time, y=value.Fix)) + 
  ggtitle(paste("Fixations >500ms over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=longFixMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p3)

p4 <- ggplot(totaldata, aes(x=time, y=value.Sac)) + 
  ggtitle(paste("Saccade speed over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sacSpMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p4)

p5 <- ggplot(totaldata, aes(x=time, y=Load, col=Load)) + 
  ggtitle(paste("Load Index\n(estimation of cognitive overload over ",window,"s)",sep="")) + 
  geom_line(size=1) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
  scale_color_gradient(low="green",high="red")
print(p5)

```

We can see how correlated these four measurements are to each other:

```{r}
#library(corrgram)

cor(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")])

#corrgram(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")], order=F, lower.panel=panel.shade,
#  upper.panel=panel.pie, text.panel=panel.txt,
#  main="Cognitive load metrics")
```

Oddly enough, **most of the correlations are negative**!


We can now save the moments of maximum and minimum (estimated) load of the teacher, for later (manual) video coding.

```{r}
interesting <- totaldata[totaldata$Load>=max(totaldata$Load) | totaldata$Load<=min(totaldata$Load),c("time","Load")]
dataToLook <- as.data.frame(interesting)
names(dataToLook)[[1]] <- "Time.ms"
dataToLook$Time.min <- msToMinSec(interesting$Time.ms)
dataToLook$Session <- session

write.csv(dataToLook, file=paste("./cleandata/InterestingEpisodes.",session,".window",window,"s.slide",slide,"s.csv",sep=""))
```


Analysis for T3S1 (Roland)
------------------------------------------------

We can inspect the different eyetracking parameters during this session, as well as our estimation of cognitive load of the teacher, calculated as **how many of these metrics surpass the median of the session**:

```{r, message=FALSE, echo=FALSE, fig.height=2, fig.width=8}
require(ggplot2)
session <- "T3S1"
load(paste("./cleandata/",session,".CognitiveLoadMetrics.rda",sep=""))

# We eliminate non-complete intervals (the end of the fixation and saccade data appears to be missing)
totaldata <- totaldata[complete.cases(totaldata),]
#**TODO: check why???**


p1 <- ggplot(totaldata, aes(x=time, y=value.Mean)) + 
  ggtitle(paste("Pupil diameter MEAN over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=meanPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p1)

p2 <- ggplot(totaldata, aes(x=time, y=value.SD)) + 
  ggtitle(paste("Pupil diameter SD over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sdPDmedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p2)

p3 <- ggplot(totaldata, aes(x=time, y=value.Fix)) + 
  ggtitle(paste("Fixations >500ms over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=longFixMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p3)

p4 <- ggplot(totaldata, aes(x=time, y=value.Sac)) + 
  ggtitle(paste("Saccade speed over ",window,"s",sep="")) + 
  geom_line() + geom_hline(yintercept=sacSpMedian) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20),axis.title=element_text(size=18))
print(p4)

p5 <- ggplot(totaldata, aes(x=time, y=Load, col=Load)) + 
  ggtitle(paste("Load Index\n(estimation of cognitive overload over ",window,"s)",sep="")) + 
  geom_line(size=1) +
  theme(axis.text.x = element_blank(),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
  scale_color_gradient(low="green",high="red")
print(p5)

```


We can see how correlated these four measurements are to each other:

```{r}
#library(corrgram)
cor(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")])

#corrgram(totaldata[,c("above.Mean","above.SD","above.Fix","above.Sac")], order=F, lower.panel=panel.shade,
#  upper.panel=panel.pie, text.panel=panel.txt,
#  main="Cognitive load metrics")
```

We can see how, again, most of the **correlations are negative, and in general quite small!**

We can now save the moments of maximum and minimum (estimated) load of the teacher, for later (manual) video coding.

```{r}
interesting <- totaldata[totaldata$Load>=max(totaldata$Load) | totaldata$Load<=min(totaldata$Load),c("time","Load")]
dataToLook <- as.data.frame(interesting)
names(dataToLook)[[1]] <- "Time.ms"
dataToLook$Time.min <- msToMinSec(interesting$Time.ms)
dataToLook$Session <- session

write.csv(dataToLook, file=paste("./cleandata/InterestingEpisodes.",session,".window",window,"s.slide",slide,"s.csv",sep=""))
```


References
--------------------------------
